{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5995787e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import timeit\n",
    "\n",
    "import os\n",
    "import sys\n",
    "root_path = os.getcwd() + \"/scripts/personal/rick\"\n",
    "sys.path.append(str(root_path))\n",
    "\n",
    "from prime_Functions_Andrew import *\n",
    "from prime_Functions_quditV2 import *\n",
    "np.set_printoptions(linewidth=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923455a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Numerical Setup - constants\n",
    "## general\n",
    "shots = 12801\n",
    "part_func = weighted_vertex_covering_maximal_cliques\n",
    "full_simulation = True\n",
    "intermediate_results_list = [6,12,25,50,100,200,400,800,1600,3200,6400,12800]\n",
    "allocation_mode = 'set'\n",
    "\n",
    "## Monte-Carlo\n",
    "N = 500\n",
    "N_max = 2001\n",
    "mcmc_shot_scale = 0\n",
    "\n",
    "## analysis\n",
    "repeats = 4\n",
    "p_noise = 0.01\n",
    "\n",
    "### Numerical Setups - variable parameters\n",
    "general_commutation_options = [True,False]\n",
    "adaptive_options = [np.array([6,12,25,50,100,200,400,800,1600,3200,6400,12800,25600,51200,102400]),np.array([0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb127b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hamiltonian\n",
    "#P,cc = read_luca_test_2(\"./Hamiltonians/\"+\"Hams\"+\"/\"+\"Periodic\"+\"/\"+ \"E_total_D3_Rick\" +\".txt\",dims=3)\n",
    "#P,cc = read_luca_test_2(\"./Hamiltonians/\"+\"Hams\"+\"/\"+\"Open\"+\"/\"+ \"D3\" +\".txt\",dims=[2,2,2,2,3])\n",
    "#P,cc = read_luca_test_2(\"./Hamiltonians/\"+\"Hams\"+\"/\"+\"Open\"+\"/\"+ \"full_D3_rev\" +\".txt\",dims=[3,2,2,2,2])\n",
    "P,cc = random_pauli_hamiltonian(20,[3,3,3])\n",
    "P,cc,pauli_block_sizes = sort_hamiltonian(P,cc)\n",
    "p,q = P.paulis(),P.qudits()\n",
    "psi = ground_state(P,cc)\n",
    "vg = variance_graph(P,cc,psi)\n",
    "\n",
    "# Simulation\n",
    "results = np.zeros((repeats,len(intermediate_results_list),6,4))\n",
    "settings = ['GC + adaptive', 'GC + non-adaptive', 'BC + adaptive', 'BC + non-adaptive','Andrew','True Covariance']\n",
    "\n",
    "for i_r in range(repeats):\n",
    "    print('repeat:',i_r)\n",
    "    start1 = timeit.default_timer()\n",
    "    i_setting = 0\n",
    "    \n",
    "    # all combination of settings\n",
    "    for general_commutation in general_commutation_options:\n",
    "        for update_steps in adaptive_options:\n",
    "            D = {}\n",
    "            print('Setting: ', settings[i_setting])\n",
    "            S,X,xxx,CG,X_list,S_list,D = bucket_filling_qudit(P,cc,psi,shots,part_func,pauli_block_sizes,\n",
    "                                                              full_simulation=full_simulation,update_steps=update_steps,\n",
    "                                                              general_commutation=general_commutation,D=D,\n",
    "                                                              M_list = intermediate_results_list,\n",
    "                                                              allocation_mode = allocation_mode,\n",
    "                                                              mcmc_shot_scale = mcmc_shot_scale,\n",
    "                                                              N_mcmc = N, N_mcmc_max = N_max,p_noise = p_noise,\n",
    "                                                              Q_progress_bar=False)\n",
    "            \n",
    "            for k,X in enumerate(X_list):\n",
    "                print('k',k)\n",
    "                S = S_list[k]\n",
    "                results[i_r,k,i_setting,0] = sum(cc[i0]*sum(X[i0,i0,i1]*math.e**(2*1j*math.pi*i1/P.lcm) for i1 in range(P.lcm))/sum(X[i0,i0,i1] for i1 in range(P.lcm)) if sum(X[i0,i0,i1] for i1 in range(P.lcm))>0 else 0 for i0 in range(p)).real\n",
    "                results[i_r,k,i_setting,1] = np.sqrt(np.sum(scale_variances(graph(bayes_covariance_graph(X,np.array(cc),CG.adj,p,pauli_block_sizes,int(P.lcm),N=N ,N_max=N_max)),S).adj)).real\n",
    "                results[i_r,k,i_setting,2] = np.sqrt(np.sum(scale_variances(vg,S).adj)).real\n",
    "                results[i_r,k,i_setting,3] = error_correction_estimation(P,cc,X,xxx[0:intermediate_results_list[k]],p_noise)\n",
    "                \n",
    "            i_setting += 1\n",
    "            print()\n",
    "            print()\n",
    "    \n",
    "    # AEQuO by Andrew\n",
    "    print('Setting: ', settings[i_setting])\n",
    "    update_steps = np.array([6,12,25,50,100,200,400,800,1600,3200,6400,12800,25600,51200,102400])\n",
    "    for k,M in enumerate(intermediate_results_list):\n",
    "        print('k',k)\n",
    "        S,X,xxx = bucket_filling_mod(P,cc,psi,M,part_func,update_steps=update_steps,repeats=(0,1),\n",
    "                                     full_simulation=True,general_commutation=True,best_possible=False)\n",
    "        results[i_r,k,i_setting,0] = sum(cc[i0]*sum(X[i0,i0][i1,i1]*math.e**(2*1j*math.pi*i1/P.lcm) for i1 in range(P.lcm))/sum(X[i0,i0][i1,i1] for i1 in range(P.lcm)) if sum(X[i0,i0][i1,i1] for i1 in range(P.lcm))>0 else 0 for i0 in range(p)).real\n",
    "        results[i_r,k,i_setting,1] = np.sqrt(np.sum(scale_variances(bayes_variance_graph(X,cc),S).adj)).real\n",
    "        results[i_r,k,i_setting,2] = np.sqrt(np.sum(scale_variances(vg,S).adj)).real\n",
    "    i_setting += 1\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    # Allocating according to true covariance\n",
    "    print('Setting: ', settings[i_setting])\n",
    "    S,X,xxx,CG,X_list,S_list,D = bucket_filling_qudit(P,cc,psi,shots,part_func,pauli_block_sizes,\n",
    "                                                      full_simulation=True,update_steps=update_steps,\n",
    "                                                      general_commutation=True,D={},\n",
    "                                                      allocation_mode = allocation_mode,\n",
    "                                                      M_list = intermediate_results_list,\n",
    "                                                      mcmc_shot_scale = mcmc_shot_scale, best_possible=True,\n",
    "                                                      N_mcmc = N, N_mcmc_max = N_max,Q_progress_bar=False)\n",
    "\n",
    "    for k,X in enumerate(X_list):\n",
    "        print('k',k)\n",
    "        S = S_list[k]\n",
    "        results[i_r,k,i_setting,0] = sum(cc[i0]*sum(X[i0,i0,i1]*math.e**(2*1j*math.pi*i1/P.lcm) for i1 in range(P.lcm))/sum(X[i0,i0,i1] for i1 in range(P.lcm)) if sum(X[i0,i0,i1] for i1 in range(P.lcm))>0 else 0 for i0 in range(p)).real\n",
    "        results[i_r,k,i_setting,1] = np.sqrt(np.sum(scale_variances(graph(bayes_covariance_graph(X,np.array(cc),CG.adj,p,pauli_block_sizes,int(P.lcm),N=N ,N_max=N_max)),S).adj)).real\n",
    "        results[i_r,k,i_setting,2] = np.sqrt(np.sum(scale_variances(vg,S).adj)).real\n",
    "        results[i_r,k,i_setting,3] = error_correction_estimation(P,cc,X,xxx,p_noise)\n",
    "        \n",
    "    stop1 = timeit.default_timer()\n",
    "    print()\n",
    "    print('Time Repeat '+ str(i_r) +' : ',stop1-start1)\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "np.save(\"Random\"+\"D3\"+\"Noise=001_Results\"+\"N\"+str(shots), results)\n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eca5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dat = intermediate_results_list\n",
    "y_dat = np.zeros((6,len(intermediate_results_list)))\n",
    "y_err_dat = np.zeros((6,len(intermediate_results_list)))\n",
    "\n",
    "n_plot = [0,1,2,3,4,5]\n",
    "H_mean = Hamiltonian_Mean(P,cc,psi).real\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2,nrows=3,figsize=(9,9))\n",
    "\n",
    "for i in n_plot: \n",
    "    for j in range(len(intermediate_results_list)): \n",
    "        y_dat[i,j] = np.mean(np.abs(results[:,j,i,0] - H_mean))\n",
    "        y_err_dat[i,j] = np.sqrt(np.mean(results[:,j,i,1]**2 + results[:,j,i,3]))\n",
    "\n",
    "        \n",
    "for i in n_plot:\n",
    "    ax[i//2,i%2].errorbar(x_dat[0:], y_dat[i,0:], yerr=y_err_dat[i,0:], fmt='o',ecolor='k',\n",
    "                 capsize=1,capthick=0.75,markersize=5,elinewidth=0.75,label=settings[i])\n",
    "\n",
    "    ax[i//2,i%2].set_xscale('log')\n",
    "    ax[i//2,i%2].set_ylabel(r'$\\tilde{O}$')\n",
    "    ax[i//2,i%2].set_xlabel(r'shots $M$')\n",
    "    ax[i//2,i%2].set_title(settings[i])\n",
    "    ax[i//2,i%2].plot([x_dat[0],x_dat[-1]],[0,0],'k--')\n",
    "    \n",
    "plt.tight_layout(pad=1, w_pad=1, h_pad=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bff6511",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dat = intermediate_results_list\n",
    "y_dat = np.zeros((6,len(intermediate_results_list)))\n",
    "y_err_dat = np.zeros((6,len(intermediate_results_list)))\n",
    "\n",
    "n_plot = [0,1,2,3,4,5]\n",
    "H_mean = Hamiltonian_Mean(P,cc,psi).real\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2,nrows=3,figsize=(9,9))\n",
    "\n",
    "for i in n_plot: \n",
    "    for j in range(len(intermediate_results_list)): \n",
    "        y_dat[i,j] = np.mean((results[:,j,i,1]**2 + results[:,j,i,3]) * intermediate_results_list[j]/ (H_mean)**2)  \n",
    "        y_err_dat[i,j] = np.std((results[:,j,i,1]**2 + results[:,j,i,3]) * intermediate_results_list[j] / (H_mean)**2) \n",
    "\n",
    "    \n",
    "y_true_dat = np.zeros((6,len(intermediate_results_list)))\n",
    "y_true_err_dat = np.zeros((6,len(intermediate_results_list)))\n",
    "for i in n_plot: \n",
    "    for j in range(len(intermediate_results_list)): \n",
    "        y_true_dat[i,j] = np.mean(results[:,j,i,2]**2 * intermediate_results_list[j]/ (H_mean)**2)  \n",
    "        y_true_err_dat[i,j] = np.std(results[:,j,i,2]**2 * intermediate_results_list[j] / (H_mean)**2)\n",
    "        \n",
    "for i in n_plot:\n",
    "    ax[i//2,i%2].errorbar(x_dat[:], y_true_dat[i,:], yerr=y_true_err_dat[i,:], fmt='s',ecolor='k',\n",
    "                 capsize=1,capthick=0.75,markersize=5,elinewidth=0.75,label=settings[i] + ' True Error')\n",
    "    ax[i//2,i%2].set_xscale('log')\n",
    "    ax[i//2,i%2].set_ylabel(r'$M \\, \\frac{(\\Delta \\tilde{O})^2}{\\tilde{O}^2}$')\n",
    "    ax[i//2,i%2].set_xlabel(r'shots $M$')\n",
    "    ax[i//2,i%2].set_title(settings[i])\n",
    "    \n",
    "for i in n_plot:\n",
    "    ax[i//2,i%2].errorbar(x_dat[:], y_dat[i,:], yerr=y_err_dat[i,:], fmt='o',ecolor='k',\n",
    "                 capsize=1,capthick=0.75,markersize=5,elinewidth=0.75,label=settings[i])\n",
    "    \n",
    "plt.tight_layout(pad=1, w_pad=1, h_pad=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e29e755",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

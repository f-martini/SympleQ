{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc49f31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from quaos.core.paulis import PauliSum, PauliString\n",
    "from quaos.core.circuits.target import find_map_to_target_pauli_sum\n",
    "from quaos.core.circuits import Gate, Circuit\n",
    "from quaos.utils import get_linear_dependencies\n",
    "from quaos.graph_utils import find_one_permutation, permutation_to_swaps, mapping_key, brute_force_all_permutations\n",
    "from quaos.models import ToricCode, Hadamard_Symmetric_PauliSum, SWAP_symmetric_PauliSum\n",
    "from scripts.experiments.symmetries.src.pauli_symmetries import symplectic_pauli_reduction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8b55cc",
   "metadata": {},
   "source": [
    "First we make a random Pauli Sum, and obtain a list of the linearly independent rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1944e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1+0j)|x1z0 x1z0 x0z1 | 0 \n",
      "(1+0j)|x0z1 x0z1 x1z1 | 0 \n",
      "(1+0j)|x1z1 x1z1 x1z1 | 0 \n",
      "(1+0j)|x1z1 x1z1 x1z0 | 0 \n",
      "\n",
      "[0, 1, 2]\n",
      "{3: [(0, 1), (1, 1)]}\n"
     ]
    }
   ],
   "source": [
    "toric = False\n",
    "hadamard_symmetry = False\n",
    "specific = True\n",
    "swap_symmetry = False\n",
    "\n",
    "if toric:\n",
    "    d = 2\n",
    "\n",
    "    Nx = 2\n",
    "    Ny = 3\n",
    "    periodic = False\n",
    "    c_x = 1.\n",
    "    c_z = 1.\n",
    "    c_g = 1.\n",
    "\n",
    "    TC = ToricCode(Nx, Ny, c_x, c_z, c_g, periodic)\n",
    "    H_tc = TC.hamiltonian()\n",
    "    print(H_tc)\n",
    "    C_reduce = symplectic_pauli_reduction(H_tc)\n",
    "    H_red = C_reduce.act(H_tc)\n",
    "    print(H_red)\n",
    "    H = H_red[:, 0:-5]  # as here there are 3 Pauli symmetries, should automate this bit\n",
    "    H.remove_trivial_paulis()\n",
    "    # print(H)\n",
    "    H.combine_equivalent_paulis()\n",
    "elif hadamard_symmetry:\n",
    "    \n",
    "    d = 2\n",
    "    n_qubits = 5\n",
    "    n_sym_q = 2\n",
    "    n_paulis = 12\n",
    "    H, C = Hadamard_Symmetric_PauliSum(n_paulis, n_qubits, n_sym_q)\n",
    "    H.combine_equivalent_paulis()\n",
    "elif swap_symmetry:\n",
    "    d = 2\n",
    "    n_qubits = 5\n",
    "    n_paulis = 12\n",
    "    H = SWAP_symmetric_PauliSum(n_paulis, n_qubits)\n",
    "    C_reduce = symplectic_pauli_reduction(H)\n",
    "    H = C_reduce.act(H)\n",
    "    # H.combine_equivalent_paulis()\n",
    "    n_paulis = H.n_paulis()\n",
    "    H.weights = np.ones(n_paulis, dtype=int)  # set all weights to 1\n",
    "\n",
    "elif specific:\n",
    "    d = 2 \n",
    "    p_string = ['x1z0 x1z0 x0z1', 'x0z1 x0z1 x1z1', 'x1z1 x1z1 x1z1', 'x1z1 x1z1 x1z0']\n",
    "    H = PauliSum(p_string, dimensions=[d, d, d], weights=[1, 1, 1, 1], standardise=False)\n",
    "    # C = Circuit.from_random(3, 100, dimensions=[d, d, d])\n",
    "    # H = C.act(H)\n",
    "    # C_reduce = symplectic_pauli_reduction(H)\n",
    "    # H = C_reduce.act(H)\n",
    "else:\n",
    "    # parameters\n",
    "    n_paulis = 20\n",
    "    n_qudits = 8\n",
    "    d = 2\n",
    "    n_weights = 1 # number of different weights\n",
    "\n",
    "    dimensions = [d] * n_qudits \n",
    "    # make a random pauli sum\n",
    "    H = PauliSum.from_random(n_paulis, n_qudits, dimensions, rand_weights=False)\n",
    "\n",
    "    # this bit makes sections of H have different weights\n",
    "    weights = np.empty(n_paulis, dtype=int)\n",
    "    section_size = n_paulis // n_weights\n",
    "    for i in range(n_weights):\n",
    "        start = i * section_size\n",
    "        end = (i + 1) * section_size if i < n_weights - 1 else n_paulis\n",
    "        weights[start:end] = i + 1\n",
    "\n",
    "    H.weights = weights\n",
    "    # print(H.symplectic())\n",
    "\n",
    "# obtain linearly independent rows - note this fails sometimes as there is a solver in it that\n",
    "# is not that robust. The Clifford approach is more robust as it creates a simple basis where the\n",
    "# dependencies can be easily read.\n",
    "print(H)\n",
    "independent_paulis, dependencies = get_linear_dependencies(H.symplectic(), d)\n",
    "\n",
    "print(independent_paulis)\n",
    "print(dependencies)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b9732a",
   "metadata": {},
   "source": [
    "We now solve for possible permutations which leave the dependencies unchanged\n",
    "\n",
    "To do so we make a dictionary with labels of the coefficients\n",
    "\n",
    "***Note this will only work for qubits for now, as for qudits we also need to account for the fact that a dependency can be made of $P_i + kP_j$ for some integer $k < d$***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88b43deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{np.complex128(1+0j): [[0], [1], [2], [0, 1]]}\n"
     ]
    }
   ],
   "source": [
    "cs = H.weights\n",
    "\n",
    "graph_dict = {}\n",
    "\n",
    "for i in independent_paulis:\n",
    "    key = cs[i]\n",
    "    if key in graph_dict:\n",
    "        graph_dict[key].append([i])\n",
    "    else:\n",
    "        graph_dict[key] = [[i]]\n",
    "\n",
    "for i in dependencies.keys():\n",
    "    key = cs[i]\n",
    "    dependency = dependencies[i]\n",
    "    dependence_indices = [x[0] for x in dependency]\n",
    "    dependence_multiplicities = [x[1] for x in dependency]  # this will be needed for qudits! always 1 for now\n",
    "    if key in graph_dict:\n",
    "        graph_dict[key].append(dependence_indices)\n",
    "    else:\n",
    "        graph_dict[key] = [dependence_indices]\n",
    "\n",
    "print(graph_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d23c40",
   "metadata": {},
   "source": [
    "We then test to see if any indexes have an automorphism that can be found via a simple swap\n",
    "\n",
    "***There is an additional condition - the pairs when swapped must leave the symplectic product matrix invariant...***\n",
    "As there is always going to be a reasonably small number of pairs, we can probably check the combinatorial number of\n",
    "options for this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b17274a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], [(0, 1)]]\n",
      "Attempting permutation 1\n",
      "[(0, 1)]\n",
      "Not an automorphism, trying next permutation\n",
      "Attempting permutation 2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No valid permutation found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m permutation = find_one_permutation(graph_dict[\u001b[32m1\u001b[39m], np.ones(\u001b[38;5;28mlen\u001b[39m(graph_dict[\u001b[32m1\u001b[39m]), dtype=\u001b[38;5;28mint\u001b[39m), permutations_attempted, \n\u001b[32m     12\u001b[39m                                    max_cycle_size=\u001b[32m300\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m permutation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo valid permutation found\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(permutation_to_swaps(permutation))\n\u001b[32m     17\u001b[39m pairs = permutation_to_swaps(permutation)\n",
      "\u001b[31mValueError\u001b[39m: No valid permutation found"
     ]
    }
   ],
   "source": [
    "\n",
    "permutation = ()\n",
    "permutations_found = set()\n",
    "permutations_attempted = set()\n",
    "found = False\n",
    "i = 0\n",
    "all_permutations = brute_force_all_permutations(graph_dict[1], np.ones(len(graph_dict[1]), dtype=int))\n",
    "print([permutation_to_swaps(perm) for perm in all_permutations])\n",
    "while not found:\n",
    "    i += 1\n",
    "    print(f\"Attempting permutation {i}\")\n",
    "    permutation = find_one_permutation(graph_dict[1], np.ones(len(graph_dict[1]), dtype=int), permutations_attempted, \n",
    "                                       max_cycle_size=300)\n",
    "    if permutation is None:\n",
    "        raise ValueError(\"No valid permutation found\")\n",
    "    \n",
    "    print(permutation_to_swaps(permutation))\n",
    "    pairs = permutation_to_swaps(permutation)\n",
    "    \n",
    "    H_target = H.copy()\n",
    "    for p in pairs:\n",
    "        H_target.swap_paulis(p[0], p[1])\n",
    "    if np.array_equal(H_target.symplectic_product_matrix(), H.symplectic_product_matrix()):\n",
    "        found = True\n",
    "        print(\"Found automorphism\")\n",
    "        break\n",
    "        # permutations_attempted.add(mapping_key(permutation, domain=sorted({x for lst in graph_dict[1] for x in lst})))\n",
    "        # permutations_found.add(mapping_key(permutation, domain=sorted({x for lst in graph_dict[1] for x in lst})))\n",
    "\n",
    "    else:\n",
    "        print(\"Not an automorphism, trying next permutation\")\n",
    "        permutations_attempted.add(mapping_key(permutation, domain=sorted({x for lst in graph_dict[1] for x in lst})))\n",
    "\n",
    "print(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34170ae2",
   "metadata": {},
   "source": [
    "Now we choose a target - for this example, performing all of these swaps\n",
    "\n",
    "We then find the symplectic which maps the original H to H_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a276cafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 1]\n",
      " [1 1 0 0 0 0 1 0 1 0]\n",
      " [0 1 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 1 1 1 0 1]\n",
      " [1 0 0 1 0 1 1 1 1 1]\n",
      " [0 0 1 1 0 1 1 0 0 0]\n",
      " [1 1 0 0 1 0 1 0 0 0]\n",
      " [1 1 0 0 1 0 0 1 0 0]\n",
      " [1 0 1 0 1 1 1 1 1 1]\n",
      " [1 0 0 1 1 0 1 0 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 0 0 0 1]]\n",
      "[[0 0 0 0 0 0 0 0 0 1]\n",
      " [1 1 0 0 0 0 1 0 1 0]\n",
      " [0 1 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 1 1 1 0 1]\n",
      " [1 0 0 1 0 1 1 1 1 1]\n",
      " [0 0 1 1 0 1 1 0 0 0]\n",
      " [1 1 0 0 1 0 1 0 0 0]\n",
      " [1 1 1 0 1 1 0 1 1 0]\n",
      " [1 0 1 0 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 1 1 0 0 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 0 0 0 1]]\n",
      "False\n",
      "[[1 0 1 0 0 1 1 0 0 0]\n",
      " [0 1 1 0 0 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0 1 0 1]\n",
      " [0 0 0 1 0 0 0 0 0 0]\n",
      " [0 1 0 1 1 0 0 1 0 1]\n",
      " [0 0 0 0 0 1 0 0 0 0]\n",
      " [0 1 0 1 0 0 1 1 0 1]\n",
      " [0 0 1 0 0 1 1 1 0 0]\n",
      " [0 1 0 1 0 0 0 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# found = False\n",
    "# # make target\n",
    "# H_target = H.copy()\n",
    "# for p in pairs:  # This is inefficient - could be done better by checking only the commutation of Paulis to be swapped\n",
    "#     H_target.swap_paulis(p[0], p[1])\n",
    "#     if np.array_equal(H_target.symplectic_product_matrix(), H.symplectic_product_matrix()):\n",
    "#         found = True\n",
    "#         print(\"Found automorphism\")\n",
    "#         break\n",
    "\n",
    "# if not found:\n",
    "#     print(\"No automorphism found - there are only non-Pauli symmetries if the rank of H is < 2n\")\n",
    "#     H_target = H.copy()\n",
    "\n",
    "\n",
    "# find F\n",
    "# It may be here that we need to use only the paulis that are linearly independent\n",
    "H_indep = H[independent_paulis]\n",
    "H_t_indep = H_target[independent_paulis]\n",
    "\n",
    "assert np.all(H_indep.symplectic_product_matrix() == H_t_indep.symplectic_product_matrix())\n",
    "\n",
    "# print(H_indep)\n",
    "# print(H_t_indep)\n",
    "\n",
    "\n",
    "F, _, _, _ = find_map_to_target_pauli_sum(H_indep, H_t_indep)\n",
    "\n",
    "# print(F)\n",
    "# check F\n",
    "# H_target.swap_paulis(3, 4)\n",
    "# H_target.swap_paulis(7, 9)\n",
    "\n",
    "\n",
    "print(H.symplectic())\n",
    "print((H_target.symplectic() @ F) % d)\n",
    "# print(H.symplectic() @ F % d)\n",
    "print(np.array_equal(H_target.symplectic(), H.symplectic() @ F % d))\n",
    "print(F)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb32464",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d146c773",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
